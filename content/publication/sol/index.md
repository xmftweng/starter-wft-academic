---
# Documentation: https://wowchemy.com/docs/managing-content/

title: A deep residual compensation extreme learning machine and applications
subtitle: ''
summary: ''
authors:
- Yinghao Chen
- Xiaoliang Xie
- Tianle Zhang
- Jiaxian Bai
- Muzhou Hou
tags: []
categories: []
date: '2020-01-01'
lastmod: 2020-10-26T06:23:32Z
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-10-26T06:23:32.213018Z'
publication_types:
- '2'
abstract: 'The extreme learning machine (ELM) is a type of machine learning algorithm for training a single hidden layer feedforward neural network. Randomly initializing the weight between the input layer and the hidden layer and the threshold of each hidden layer neuron, the weight matrix of the hidden layer can be calculated by the least squares method. The efficient learning ability in ELM makes it widely applicable in classification, regression, and more. However, owing to some unutilized information in the residual, there are relatively huge prediction errors involving ELM. In this paper, a deep residual compensation extreme learning machine model (DRC‐ELM) of multilayer structures applied to regression is presented. The first layer is the basic ELM layer, which helps in obtaining an approximation of the objective function by learning the characteristics of the sample. The other layers are the residual compensation layers in which the learned residual is corrected layer by layer to the predicted value obtained in the previous layer by constructing a feature mapping between the input layer and the output of the upper layer. This model is applied to two practical problems: gold price forecasting and airfoil self‐noise prediction. We used the DRC‐ELM with 50, 100, and 200 residual compensation layers respectively for experiments, which show that DRC‐ELM does better in generalization and robustness than classical ELM, improved ELM models such as GA‐RELM and OS‐ELM, and other traditional machine learning algorithms such as support vector machine (SVM) and back‐propagation neural network (BPNN).'
publication: '*Journal of Forecasting*'
---
